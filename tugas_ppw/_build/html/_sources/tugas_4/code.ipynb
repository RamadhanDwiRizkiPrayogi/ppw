{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.32.5)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.13.5)\n",
      "Requirement already satisfied: lxml in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (6.0.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests) (2025.8.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from beautifulsoup4) (2.7)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from beautifulsoup4) (4.14.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: openpyxl in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.1.5)\n",
      "Requirement already satisfied: xlsxwriter in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.2.9)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openpyxl) (2.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: openpyxl in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.1.5)\n",
      "Requirement already satisfied: xlsxwriter in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.2.9)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openpyxl) (2.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install requests beautifulsoup4 lxml\n",
    "%pip install openpyxl xlsxwriter\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import re\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Total data dikumpulkan: 1,031\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No</th>\n",
       "      <th>Abstrak</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Satiyah, Pengaruh Faktor-faktor Pelatihan dan ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tujuan penelitian ini adalah untuk mengetahui ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Aplikasi nyata pemanfaatan teknologi informasi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Penelitian ini menggunakan metode kuantitatif,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1026</th>\n",
       "      <td>1027</td>\n",
       "      <td>Penelitian ini bertujuan untuk mengetahui perh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1027</th>\n",
       "      <td>1028</td>\n",
       "      <td>Uswatun Hasanah, 160211100291, Pengaruh Pelati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1028</th>\n",
       "      <td>1029</td>\n",
       "      <td>Tujuan dari penelitian ini adalah untuk menget...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1029</th>\n",
       "      <td>1030</td>\n",
       "      <td>Penelitian ini bertujuan: (1) Untuk mengetahui...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1030</th>\n",
       "      <td>1031</td>\n",
       "      <td>Penelitian ini bertujuan untuk dapat mengetahu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1031 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        No                                            Abstrak\n",
       "0        1  Satiyah, Pengaruh Faktor-faktor Pelatihan dan ...\n",
       "1        2  Tujuan penelitian ini adalah untuk mengetahui ...\n",
       "2        3                                                   \n",
       "3        4  Aplikasi nyata pemanfaatan teknologi informasi...\n",
       "4        5  Penelitian ini menggunakan metode kuantitatif,...\n",
       "...    ...                                                ...\n",
       "1026  1027  Penelitian ini bertujuan untuk mengetahui perh...\n",
       "1027  1028  Uswatun Hasanah, 160211100291, Pengaruh Pelati...\n",
       "1028  1029  Tujuan dari penelitian ini adalah untuk menget...\n",
       "1029  1030  Penelitian ini bertujuan: (1) Untuk mengetahui...\n",
       "1030  1031  Penelitian ini bertujuan untuk dapat mengetahu...\n",
       "\n",
       "[1031 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "BASE_URL = \"https://pta.trunojoyo.ac.id/c_search/byprod\"\n",
    "\n",
    "def get_max_page(prodi_id):\n",
    "    \"\"\"Mendapatkan jumlah halaman maksimal untuk prodi tertentu\"\"\"\n",
    "    try:\n",
    "        url = f\"{BASE_URL}/{prodi_id}/1\"\n",
    "        response = requests.get(url, timeout=10)\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "        \n",
    "        pagination = soup.select('a[href*=\"byprod\"]')\n",
    "        if pagination:\n",
    "            last_page = 1\n",
    "            for link in pagination:\n",
    "                href = link.get('href', '')\n",
    "                if f'/byprod/{prodi_id}/' in href:\n",
    "                    page_match = re.search(rf'/byprod/{prodi_id}/(\\d+)', href)\n",
    "                    if page_match:\n",
    "                        page_num = int(page_match.group(1))\n",
    "                        last_page = max(last_page, page_num)\n",
    "            return last_page\n",
    "        return 1\n",
    "    except:\n",
    "        return 1\n",
    "\n",
    "def pta():\n",
    "    \"\"\"Fungsi utama untuk scraping data PTA\"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    data = {\n",
    "        \"judul\": [], \"abstrak_id\": [], \"abstrak_en\": []\n",
    "    }\n",
    "    \n",
    "    prodi_id = 7\n",
    "    prodi_name = \"Manajemen\"\n",
    "    \n",
    "    # Get max pages\n",
    "    max_page = get_max_page(prodi_id)\n",
    "    \n",
    "    for j in range(1, max_page + 1):\n",
    "        try:\n",
    "            url = f\"{BASE_URL}/{prodi_id}/{j}\"\n",
    "            r = requests.get(url, timeout=15)\n",
    "            soup = BeautifulSoup(r.content, \"html.parser\")\n",
    "            jurnals = soup.select('li[data-cat=\"#luxury\"]')\n",
    "            \n",
    "            # Process setiap jurnal\n",
    "            for jurnal in jurnals:\n",
    "                try:\n",
    "                    link_keluar = jurnal.select_one('a.gray.button')['href']\n",
    "                    \n",
    "                    response = requests.get(link_keluar, timeout=15)\n",
    "                    soup1 = BeautifulSoup(response.content, \"html.parser\")\n",
    "                    isi = soup1.select_one('div#content_journal')\n",
    "                    \n",
    "                    if not isi:\n",
    "                        continue\n",
    "                    \n",
    "                    # Extract data\n",
    "                    judul = isi.select_one('a.title').text.strip()\n",
    "                    \n",
    "                    # Extract abstrak\n",
    "                    paragraf = isi.select('p[align=\"justify\"]')\n",
    "                    abstrak_id = paragraf[0].get_text(strip=True) if len(paragraf) > 0 else \"N/A\"\n",
    "                    abstrak_en = paragraf[1].get_text(strip=True) if len(paragraf) > 1 else \"N/A\"\n",
    "                    \n",
    "                    # Clean abstrak Indonesia\n",
    "                    if abstrak_id != \"N/A\" and abstrak_id.upper().startswith('ABSTRAK'):\n",
    "                        abstrak_id = abstrak_id[7:].strip()\n",
    "                    \n",
    "                    # Append data\n",
    "                    data[\"judul\"].append(judul)\n",
    "                    data[\"abstrak_id\"].append(abstrak_id)\n",
    "                    data[\"abstrak_en\"].append(abstrak_en)\n",
    "                    \n",
    "                    time.sleep(0.1)\n",
    "                    \n",
    "                except:\n",
    "                    continue\n",
    "            \n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    # Buat DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Summary\n",
    "    print(f\"ðŸ“Š Total data dikumpulkan: {len(df):,}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Jalankan scraping\n",
    "result_df = pta()\n",
    "\n",
    "# Ambil abstrak Indonesia untuk corpus\n",
    "corpus = result_df[result_df['abstrak_id'] != 'N/A']['abstrak_id'].tolist()\n",
    "\n",
    "# Tampilkan dalam bentuk DataFrame (semua data)\n",
    "import pandas as pd\n",
    "df_sample = pd.DataFrame({\n",
    "    'No': range(1, len(corpus) + 1),\n",
    "    'Abstrak': corpus\n",
    "})\n",
    "\n",
    "df_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "11UFB9KvOQyP"
   },
   "source": [
    "### **1. Pembersihan Teks**\n",
    "\n",
    "**Pembersihan teks** adalah tahap preprocessing untuk menormalkan data teks agar konsisten dan siap dianalisis. Proses ini meliputi: mengubah teks ke huruf kecil (lowercasing), menghapus angka, menghilangkan tanda baca, dan membersihkan spasi berlebih. Tujuannya adalah mengurangi variasi yang tidak perlu dan memfokuskan analisis pada konten tekstual yang bermakna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hasil Pembersihan Teks:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstrak_asli</th>\n",
       "      <th>abstrak_bersih</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Satiyah, Pengaruh Faktor-faktor Pelatihan dan ...</td>\n",
       "      <td>satiyah pengaruh faktorfaktor pelatihan dan pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tujuan penelitian ini adalah untuk mengetahui ...</td>\n",
       "      <td>tujuan penelitian ini adalah untuk mengetahui ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aplikasi nyata pemanfaatan teknologi informasi...</td>\n",
       "      <td>aplikasi nyata pemanfaatan teknologi informasi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Penelitian ini menggunakan metode kuantitatif,...</td>\n",
       "      <td>penelitian ini menggunakan metode kuantitatif ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Aththaariq, Pengaruh Kompetensi Dosen Terhadap...</td>\n",
       "      <td>aththaariq pengaruh kompetensi dosen terhadap ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Haryono Arifin, Pengaruh Perilaku Konsumen Ter...</td>\n",
       "      <td>haryono arifin pengaruh perilaku konsumen terh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Dharma Abidin Syah,Kesimpulan: (1) Terdapat pe...</td>\n",
       "      <td>dharma abidin syahkesimpulan terdapat pengaruh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Tujuan penelitian ini adalah untuk mengidentif...</td>\n",
       "      <td>tujuan penelitian ini adalah untuk mengidentif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Hasil dari penelitian ini dari perhitungan Cre...</td>\n",
       "      <td>hasil dari penelitian ini dari perhitungan cre...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        abstrak_asli  \\\n",
       "0  Satiyah, Pengaruh Faktor-faktor Pelatihan dan ...   \n",
       "1  Tujuan penelitian ini adalah untuk mengetahui ...   \n",
       "2                                                      \n",
       "3  Aplikasi nyata pemanfaatan teknologi informasi...   \n",
       "4  Penelitian ini menggunakan metode kuantitatif,...   \n",
       "5  Aththaariq, Pengaruh Kompetensi Dosen Terhadap...   \n",
       "6  Haryono Arifin, Pengaruh Perilaku Konsumen Ter...   \n",
       "7  Dharma Abidin Syah,Kesimpulan: (1) Terdapat pe...   \n",
       "8  Tujuan penelitian ini adalah untuk mengidentif...   \n",
       "9  Hasil dari penelitian ini dari perhitungan Cre...   \n",
       "\n",
       "                                      abstrak_bersih  \n",
       "0  satiyah pengaruh faktorfaktor pelatihan dan pe...  \n",
       "1  tujuan penelitian ini adalah untuk mengetahui ...  \n",
       "2                                                     \n",
       "3  aplikasi nyata pemanfaatan teknologi informasi...  \n",
       "4  penelitian ini menggunakan metode kuantitatif ...  \n",
       "5  aththaariq pengaruh kompetensi dosen terhadap ...  \n",
       "6  haryono arifin pengaruh perilaku konsumen terh...  \n",
       "7  dharma abidin syahkesimpulan terdapat pengaruh...  \n",
       "8  tujuan penelitian ini adalah untuk mengidentif...  \n",
       "9  hasil dari penelitian ini dari perhitungan cre...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pembersihan teks\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def clean_text(text):\n",
    "    # Ubah ke huruf kecil\n",
    "    text = text.lower()\n",
    "    # Hapus angka\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    # Hapus tanda baca\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    # Hapus spasi berlebih\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "# Terapkan pembersihan teks\n",
    "cleaned_corpus = [clean_text(text) for text in corpus]\n",
    "\n",
    "# Tampilkan hasil pembersihan teks dalam format DataFrame\n",
    "comparison_df = pd.DataFrame({\n",
    "    'abstrak_asli': corpus[:10],\n",
    "    'abstrak_bersih': cleaned_corpus[:10]\n",
    "})\n",
    "\n",
    "print(\"\\nHasil Pembersihan Teks:\")\n",
    "comparison_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k9j1pNkvOVKo"
   },
   "source": [
    "### **2. Tokenisasi**\n",
    "\n",
    "**Tokenisasi** adalah proses memecah teks menjadi unit-unit yang lebih kecil seperti kata atau token. Pada tahap ini, setiap kalimat dalam abstrak dipecah menjadi kata-kata individual menggunakan `word_tokenize` dari NLTK. Contoh: kalimat \"Penelitian ini menganalisis data\" â†’ ['Penelitian', 'ini', 'menganalisis', 'data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yAJTtGY7OXCP",
    "outputId": "a22fe187-e3b5-4da4-a808-757a191de6e7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PTA (abstrak_id_tokens):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstrak_id_clean</th>\n",
       "      <th>abstrak_id_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>satiyah pengaruh faktorfaktor pelatihan dan pe...</td>\n",
       "      <td>[satiyah, pengaruh, faktorfaktor, pelatihan, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tujuan penelitian ini adalah untuk mengetahui ...</td>\n",
       "      <td>[tujuan, penelitian, ini, adalah, untuk, menge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aplikasi nyata pemanfaatan teknologi informasi...</td>\n",
       "      <td>[aplikasi, nyata, pemanfaatan, teknologi, info...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>penelitian ini menggunakan metode kuantitatif ...</td>\n",
       "      <td>[penelitian, ini, menggunakan, metode, kuantit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>aththaariq pengaruh kompetensi dosen terhadap ...</td>\n",
       "      <td>[aththaariq, pengaruh, kompetensi, dosen, terh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>haryono arifin pengaruh perilaku konsumen terh...</td>\n",
       "      <td>[haryono, arifin, pengaruh, perilaku, konsumen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>dharma abidin syahkesimpulan terdapat pengaruh...</td>\n",
       "      <td>[dharma, abidin, syahkesimpulan, terdapat, pen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>tujuan penelitian ini adalah untuk mengidentif...</td>\n",
       "      <td>[tujuan, penelitian, ini, adalah, untuk, mengi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>hasil dari penelitian ini dari perhitungan cre...</td>\n",
       "      <td>[hasil, dari, penelitian, ini, dari, perhitung...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    abstrak_id_clean  \\\n",
       "0  satiyah pengaruh faktorfaktor pelatihan dan pe...   \n",
       "1  tujuan penelitian ini adalah untuk mengetahui ...   \n",
       "2                                                      \n",
       "3  aplikasi nyata pemanfaatan teknologi informasi...   \n",
       "4  penelitian ini menggunakan metode kuantitatif ...   \n",
       "5  aththaariq pengaruh kompetensi dosen terhadap ...   \n",
       "6  haryono arifin pengaruh perilaku konsumen terh...   \n",
       "7  dharma abidin syahkesimpulan terdapat pengaruh...   \n",
       "8  tujuan penelitian ini adalah untuk mengidentif...   \n",
       "9  hasil dari penelitian ini dari perhitungan cre...   \n",
       "\n",
       "                                   abstrak_id_tokens  \n",
       "0  [satiyah, pengaruh, faktorfaktor, pelatihan, d...  \n",
       "1  [tujuan, penelitian, ini, adalah, untuk, menge...  \n",
       "2                                                 []  \n",
       "3  [aplikasi, nyata, pemanfaatan, teknologi, info...  \n",
       "4  [penelitian, ini, menggunakan, metode, kuantit...  \n",
       "5  [aththaariq, pengaruh, kompetensi, dosen, terh...  \n",
       "6  [haryono, arifin, pengaruh, perilaku, konsumen...  \n",
       "7  [dharma, abidin, syahkesimpulan, terdapat, pen...  \n",
       "8  [tujuan, penelitian, ini, adalah, untuk, mengi...  \n",
       "9  [hasil, dari, penelitian, ini, dari, perhitung...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "import pandas as pd\n",
    "\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "# Tokenisasi untuk PTA\n",
    "# Buat DataFrame dari corpus yang sudah dibersihkan\n",
    "pta_df = pd.DataFrame({\n",
    "    'abstrak_id_clean': cleaned_corpus\n",
    "})\n",
    "\n",
    "pta_df[\"abstrak_id_tokens\"] = pta_df[\"abstrak_id_clean\"].apply(word_tokenize)\n",
    "\n",
    "print(\"\\nPTA (abstrak_id_tokens):\")\n",
    "pta_df[[\"abstrak_id_clean\", \"abstrak_id_tokens\"]].head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7MJMFTQVOarI"
   },
   "source": [
    "### **3. Penghapusan Kata Umum (Stop Words)**\n",
    "\n",
    "**Stop Words** adalah kata-kata umum yang sering muncul dalam bahasa namun tidak memberikan makna signifikan untuk analisis teks, seperti \"dan\", \"atau\", \"di\", \"ke\", \"yang\". Penghapusan stopwords bertujuan untuk mengurangi noise dan fokus pada kata-kata yang lebih bermakna untuk analisis. NLTK menyediakan daftar stopwords bahasa Indonesia yang sudah siap pakai."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PKkRL87EOben",
    "outputId": "775733a7-511b-447e-c341-f1c5b46a2274"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PTA (abstrak_id_filtered):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstrak_id_tokens</th>\n",
       "      <th>abstrak_id_filtered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[satiyah, pengaruh, faktorfaktor, pelatihan, d...</td>\n",
       "      <td>[satiyah, pengaruh, faktorfaktor, pelatihan, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[tujuan, penelitian, ini, adalah, untuk, menge...</td>\n",
       "      <td>[tujuan, penelitian, persepsi, brand, associat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[aplikasi, nyata, pemanfaatan, teknologi, info...</td>\n",
       "      <td>[aplikasi, nyata, pemanfaatan, teknologi, info...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[penelitian, ini, menggunakan, metode, kuantit...</td>\n",
       "      <td>[penelitian, metode, kuantitatif, menekankan, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[aththaariq, pengaruh, kompetensi, dosen, terh...</td>\n",
       "      <td>[aththaariq, pengaruh, kompetensi, dosen, kine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[haryono, arifin, pengaruh, perilaku, konsumen...</td>\n",
       "      <td>[haryono, arifin, pengaruh, perilaku, konsumen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[dharma, abidin, syahkesimpulan, terdapat, pen...</td>\n",
       "      <td>[dharma, abidin, syahkesimpulan, pengaruh, sig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[tujuan, penelitian, ini, adalah, untuk, mengi...</td>\n",
       "      <td>[tujuan, penelitian, mengidentifikasi, variabe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[hasil, dari, penelitian, ini, dari, perhitung...</td>\n",
       "      <td>[hasil, penelitian, perhitungan, credit, risk,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   abstrak_id_tokens  \\\n",
       "0  [satiyah, pengaruh, faktorfaktor, pelatihan, d...   \n",
       "1  [tujuan, penelitian, ini, adalah, untuk, menge...   \n",
       "2                                                 []   \n",
       "3  [aplikasi, nyata, pemanfaatan, teknologi, info...   \n",
       "4  [penelitian, ini, menggunakan, metode, kuantit...   \n",
       "5  [aththaariq, pengaruh, kompetensi, dosen, terh...   \n",
       "6  [haryono, arifin, pengaruh, perilaku, konsumen...   \n",
       "7  [dharma, abidin, syahkesimpulan, terdapat, pen...   \n",
       "8  [tujuan, penelitian, ini, adalah, untuk, mengi...   \n",
       "9  [hasil, dari, penelitian, ini, dari, perhitung...   \n",
       "\n",
       "                                 abstrak_id_filtered  \n",
       "0  [satiyah, pengaruh, faktorfaktor, pelatihan, p...  \n",
       "1  [tujuan, penelitian, persepsi, brand, associat...  \n",
       "2                                                 []  \n",
       "3  [aplikasi, nyata, pemanfaatan, teknologi, info...  \n",
       "4  [penelitian, metode, kuantitatif, menekankan, ...  \n",
       "5  [aththaariq, pengaruh, kompetensi, dosen, kine...  \n",
       "6  [haryono, arifin, pengaruh, perilaku, konsumen...  \n",
       "7  [dharma, abidin, syahkesimpulan, pengaruh, sig...  \n",
       "8  [tujuan, penelitian, mengidentifikasi, variabe...  \n",
       "9  [hasil, penelitian, perhitungan, credit, risk,...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "\n",
    "# Download stopwords untuk bahasa Indonesia\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Stopwords untuk bahasa Indonesia\n",
    "stop_words_id = set(stopwords.words('indonesian'))\n",
    "\n",
    "# Filter stopwords di PTA\n",
    "pta_df[\"abstrak_id_filtered\"] = pta_df[\"abstrak_id_tokens\"].apply(\n",
    "    lambda tokens: [word for word in tokens if word not in stop_words_id]\n",
    ")\n",
    "\n",
    "print(\"\\nPTA (abstrak_id_filtered):\")\n",
    "pta_df[[\"abstrak_id_tokens\", \"abstrak_id_filtered\"]].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sCT0BB3ZOdMY"
   },
   "source": [
    "### **4. Stemming dan Lematisasi**\n",
    "\n",
    "**Stemming** adalah proses mengubah kata-kata menjadi bentuk dasar (root/stem) dengan menghilangkan imbuhan seperti awalan, akhiran, dan sisipan. Contoh: \"penelitian\" â†’ \"teliti\", \"menganalisis\" â†’ \"analisis\". **Lematisasi** serupa dengan stemming namun menghasilkan kata dasar yang lebih bermakna secara linguistik. Pada kode ini menggunakan library Sastrawi untuk stemming bahasa Indonesia dan TF-IDF untuk mengukur kepentingan kata dalam dokumen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x1Q44O9SOfwx",
    "outputId": "8b5d33a6-0d03-4c67-a75f-76f72719f2e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "satiyah pengaruh faktorfaktor latih kembang produktivitas kerja dinas laut ikan bangkal bawah bimbing drahjsanugrahini irawatimm helm buyung auliasstsemmt upaya tingkat produktivitas kerja mudah salah usaha produktivitas tingkat terap program latih kembang sumber daya manusia sdm laksana instansi produktivitas capai tingkat mampu pegawai efektif efisien latih pengembnagan harap pegawai sesuai kebutuhankebutuhan sikap tingkah laku terampil tahu sesuai tuntut ubah latih kembang pegawai dukung cipta suasana kerja kondusif instansi produktivitas kerja tingkat tuju teliti pengaruh faktorfaktor latih kembang produktivitas kerja dinas laut ikan bangkal ukur menganalisa hubung variabel teliti dekat observasional analitik amat langsung responden sebar kuisioner analis teliti teliti populasi responden sampel olah spss versi analis metode statistik metode non probality sampling simple random sampling simpul teliti a faktorfaktor latih kembang beda individu pegawai x hubung analisis jabat x motivasi x partisipasi aktif x seleksi serta x seleksi instruktur x metode latih kembang x pengaruh simultan produktivitas kerja pegawai dinas laut ikan kabupaten bangkal bukti nilai koefisien determinasi ganda r r square fhitung ftabel b faktor hubung analisis jabat pengaruh parsial produktivitas kerja pegawai dinas laut ikan kabupaten bangkal uji hipotesis variabel motivasi x bukti nilai thitung seleksi serta x pengaruh dominan produktivitas kerja pegawai instansi dinas laut ikan bangkal kunci dinas laut ikan faktorfaktor latih kembang produktivitas kerja\n",
      "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
      "\twith 62537 stored elements and shape (1031, 6475)>\n",
      "  Coords\tValues\n",
      "  (0, 5117)\t0.06722909312737141\n",
      "  (0, 4191)\t0.0541516702031106\n",
      "  (0, 1659)\t0.14269167120886075\n",
      "  (0, 3096)\t0.3419521854596088\n",
      "  (0, 2689)\t0.2310267040658058\n",
      "  (0, 4529)\t0.4241844729957941\n",
      "  (0, 2737)\t0.14776812022071217\n",
      "  (0, 1274)\t0.24247402690069209\n",
      "  (0, 3099)\t0.3422172695416197\n",
      "  (0, 2170)\t0.3422172695416197\n",
      "  (0, 565)\t0.13115632018860826\n",
      "  (0, 615)\t0.017685349056678706\n",
      "  (0, 749)\t0.014704490440205433\n",
      "  (0, 1374)\t0.05872778381208961\n",
      "  (0, 2376)\t0.04986258626517635\n",
      "  (0, 2030)\t0.035368695117738866\n",
      "  (0, 858)\t0.03567291780221519\n",
      "  (0, 491)\t0.06722909312737141\n",
      "  (0, 6182)\t0.04853490227498815\n",
      "  (0, 5973)\t0.07313060697977133\n",
      "  (0, 3662)\t0.0454131261181226\n",
      "  (0, 5045)\t0.029088567353457058\n",
      "  (0, 6192)\t0.01607571840857942\n",
      "  (0, 5892)\t0.03920571001602217\n",
      "  (0, 4556)\t0.032774717779635684\n",
      "  :\t:\n",
      "  (1030, 6112)\t0.055849694747306416\n",
      "  (1030, 3013)\t0.022333743758070956\n",
      "  (1030, 587)\t0.07090377689539146\n",
      "  (1030, 2921)\t0.060379964180943234\n",
      "  (1030, 4493)\t0.2350619392012171\n",
      "  (1030, 2598)\t0.08840301812553714\n",
      "  (1030, 5349)\t0.09884747636372776\n",
      "  (1030, 2949)\t0.17320503439401574\n",
      "  (1030, 3703)\t0.10404077977456368\n",
      "  (1030, 3170)\t0.217764671836858\n",
      "  (1030, 5685)\t0.13772822035300814\n",
      "  (1030, 5210)\t0.32735961265474545\n",
      "  (1030, 1466)\t0.3570267232638322\n",
      "  (1030, 3369)\t0.1407467242108548\n",
      "  (1030, 2993)\t0.11900890775461075\n",
      "  (1030, 856)\t0.08180467455076844\n",
      "  (1030, 6198)\t0.11115953760380255\n",
      "  (1030, 3094)\t0.09385618099923122\n",
      "  (1030, 1948)\t0.20808155954912735\n",
      "  (1030, 2930)\t0.11343969100261525\n",
      "  (1030, 1469)\t0.11900890775461075\n",
      "  (1030, 3775)\t0.13242749465741444\n",
      "  (1030, 3419)\t0.14027686480822266\n",
      "  (1030, 2833)\t0.2805537296164453\n",
      "  (1030, 1857)\t0.2805537296164453\n"
     ]
    }
   ],
   "source": [
    "import Sastrawi\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()\n",
    "\n",
    "# Test stemming dengan satu dokumen\n",
    "input_stemm = str(pta_df[\"abstrak_id_filtered\"].iloc[0])\n",
    "hasil_stemm = stemmer.stem(input_stemm)\n",
    "print(hasil_stemm)\n",
    "\n",
    "# Stemming untuk semua dokumen\n",
    "hasil_stemm = []\n",
    "for doc in pta_df[\"abstrak_id_filtered\"]:\n",
    "    stemmed_doc = [stemmer.stem(word) for word in doc]\n",
    "    hasil_stemm.append(stemmed_doc)\n",
    "\n",
    "# Konversi hasil stemming ke string untuk TF-IDF\n",
    "stemmed_texts = [' '.join(doc) for doc in hasil_stemm]\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "x = vectorizer.fit_transform(stemmed_texts)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5. Analisis Frekuensi Kata**\n",
    "\n",
    "**Analisis Frekuensi** adalah proses menghitung seberapa sering setiap kata muncul dalam corpus setelah melalui tahap preprocessing. Menggunakan `FreqDist` dari NLTK untuk menghitung distribusi frekuensi kata dan mengidentifikasi kata-kata yang paling sering muncul. Hasil analisis ini disimpan dalam format CSV untuk analisis lebih lanjut dan memberikan insight tentang tema-tema utama dalam dokumen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File disimpan sebagai Management_dataHasilPreprocessing.csv\n"
     ]
    }
   ],
   "source": [
    "from nltk import FreqDist\n",
    "import pandas as pd\n",
    "\n",
    "# Gabungkan semua kata dari hasil stemming\n",
    "all_words = []\n",
    "for doc in hasil_stemm:\n",
    "    all_words.extend(doc)\n",
    "\n",
    "fdist = FreqDist(all_words)\n",
    "\n",
    "frequency_df = pd.DataFrame(\n",
    "    fdist.most_common(),\n",
    "    columns=['Word', 'Frequency']\n",
    ")\n",
    "\n",
    "frequency_df.to_csv('Management_dataHasilPreprocessing.csv', index=False, encoding='utf-8-sig')\n",
    "print(\"File disimpan sebagai Management_dataHasilPreprocessing.csv\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
